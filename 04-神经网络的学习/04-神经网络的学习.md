“学习”,是指从训练数据中自动获取最优权重参数的过程。
参考之前学习的感知机，和用感知机实现的逻辑门。因输入少，所以可以人工确定参数（偏置）的值。但在其他场景，参数可能有成千上万。
人工确定参数的值就变得不可能。

# 训练数据和测试数据
用训练数据（又称为监督数据）来学习，寻找最优秀的参数。
用测试数据来验证模型的实际能力。
这样设计的目的是，追求模型的泛化能力。
泛化能力指处理未被训练过的数据的能力。

# 损失函数
损失函数用来估量模型的预测值与真实值之间的不一致程度。损失值越小，表示两个值越接近，预测更准确。

# 数值微分与导数
f(x)在某个瞬间的变化量。
微小变化h无限趋近0，表示为dh/dx。 (f(x+h) - f(x)) / h。
该方法称为数值微分，计算的是（x + h）与x的斜率（称为切线）。因此，真的导数与此处计算的导数有差别，因为h不可能真的无限接近0.
为了减小该误差，可以采用中心差分。即计算(f(x + h) - f(x - h)) / 2h.

# 偏导数
函数里有两个变量，x0， x1。有多个变量的函数的导数称为偏导数。
要区分是对哪个变量求导。

# 梯度
所有变量的偏导数汇总而成的 向量 称为梯度。
梯度非常重要的性质：梯度指示的方向是各点处的函数值减小最多的方向。

# 梯度法 gradient method
* 机器学习的主要任务是在学习时寻找最优参数。
* 神经网络必须在学习时找到最优参数（权重和偏置）。这里所说的参数是使损失最小的参数。但通常损失函数很复杂，参数空间庞大，很难知道在何处能取到最小值。
* 使用梯度来寻找函数最小（或尽可能小）值的方法就是梯度法。
* 梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。
* 梯度法中，从当前位置沿着梯度方向前进一段距离，在新的地方重新求梯度，再沿着新梯度方向前进。如此反复，逐渐减小函数值的过程就是梯度法。
* 根据是寻找最小值或最大值，梯度法分为梯度上升法和梯度下降法。

# 学习率 learn rate / lr
学习率决定在一次学习中，应该学习多少，以及在多大程度上更新参数。
需要事先确定为某个值，0.01或0.001.一般会边改变它的值，边确认学习是否正确进行。

# 梯度法求f(x0 + x1) = x0^2 + x1^2的最小值
见04.py func_2(),以及gradient_descent().
lr分别设为0.01、0.1、10，计算100次，得出的结果是
[-0.39785867  0.53047822]
[-8.10452420e-11  1.08060323e-10]
[-1.29863664e+13  1.28237547e+13]

可见适合的lr设置很重要。
- 学习率太小：收敛速度慢
- 学习率太大：可能无法收敛或收敛到错误的结果
- 需要根据具体问题选择合适的学习率

权重参数是通过训练数据和学习算法自动获得的，学习率这样的超参数则是人工设定的。

# 用数值微分求梯度 训练神经网络
代码见train_neuralnet.py，准确率变化见图 识别准确率变化.png
- 梯度算法为数值微分（第五章 改用误差反向传播算法，以进行比较）
- learning_rate = 0.1 ：学习率固定为0.1
- iters_num = 10000 ：总共进行10000次迭代训练
- batch_size = 100 ：每次迭代随机选取100张图片作为一个批次
- batch_mask = np.random.choice(train_size, batch_size) ：使用numpy的random.choice函数从训练集（大小为train_size）中随机选择100个样本的索引

准确率前期提升很快，到了90%之后，提升幅度就很小。
原因是学习率过大，导致权重参数在正确的更新方向上过大，从而发散而不是收敛。

代码执行5次，最终识别准确率0.94。回显分别为：
第9600次 打印train acc : 0.9464, test acc : 0.9441
第9600次 打印train acc : 0.9465, test acc : 0.9447
第9600次 打印train acc : 0.9458, test acc : 0.9459
第9600次 打印train acc : 0.9449, test acc : 0.9431
第9600次 打印train acc : 0.9476, test acc : 0.9456

# 学习算法的实现
神经网络学习分为四个步骤：
1. 小批量（mini-batch） 从训练数据中随机选出一部分数据
2. 计算梯度 计算损失函数关于各个权重参数的梯度。梯度表示损失函数的值减小最多的方向。
3. 将权重参数沿梯度方向进行微小更新（根据学习率逐次更新变量值）。
4. 重复步骤1-3