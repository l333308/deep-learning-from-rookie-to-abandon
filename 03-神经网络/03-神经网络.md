上一章，学习了如何用感知机实现逻辑门。
但，确定合适的、能符合预期的输入与输出的权重，现在还是由人工进行的。
神经网络解决了该问题。它可以自动地从数据中学习到合适的权重参数。

# 函数表达式的转化
之前看或门，y = b + (x1 * w1 + x2 * w2)，此表达式可以简化为x的线性函数，记为y = h(x)。

# 激活函数
将输入信号的总和转换为输出信号，这种函数称为激活函数。
y = h(a)，用h()函数将a转换为输出y。

# 阶跃函数
式3.3表示的激活函数以阈值为界，当输入超过阈值，则切换输出。这样的函数称为阶跃函数。
什么破翻译，为什么不叫“突变函数”。
代码实现见03.py step_function(),图示见阶跃函数.png。
可见，以x轴的0值为界，输出从0跃升为1。

# 对比阶跃函数与sigmoid函数
见图 阶跃函数 - sig函数.png。
sigmoid函数是一条平滑的曲线，输出随着输入发生连续性的变化。
该函数的平滑性对神经网络的学习具有重要意义。
两者都是非（直）线性函数。

# relu函数
在输入大于0时，直接输出该值；在输入小于等于0时，输出0。

# 多维数组的运算
numpy后文记为np。
对于np.array(),可通过np.dim()获取其维数，np.shape获取其形状（几行几列）。
* 对于二维数组（矩阵） [[1, 2, 3], [3, 4, 5]] ，其形状为 (2, 3) ，表示有2行3列
* 二维数组称为矩阵（matrix）。

# 矩阵乘法
计算规则有点特别，与线性代数中的矩阵乘法不同。用np.dot()实现。
注：矩阵A * 矩阵B，记为A * B。
* 矩阵A的列数要与矩阵B的行数相同。
* A的行 * B的列，对应相乘，再求和。
* 乘积 shape为 (A的行数, B的列数)

# 机器学习 分类问题 回归问题
机器学习的问题，大致可以分为分类问题、回归问题。
分类：数据属于哪一个类别。比如，区分图像中是男性还是女性。
回归：是根据某个输入预测一个（连续的）数值的问题。如，根据图像预测体重（类似“57.4kg”这样的预测）。

# 恒等函数 与 softmax函数
恒等函数：输入信号原封不动地输出。

softmax函数：将输入信号转换为输出信号。
softmax函数的计算步骤：
1. 对输入信号进行指数函数的转换，将所有元素变为正数。
2. 对转换后的元素进行和的运算，得到各个元素的和。
3. 将和作为分母，对各个元素进行除法运算。
看起来，softmax函数，是计算每个元素，加权之后的占比。所有元素之和为1。情感分析？

实现softmax函数，见03.py softmax()。
有个注意点，数值溢出问题。e100会变成一个后面有40多个0的超大值，e1000的结果会返回一个表示无穷大的int。

# softmax 防溢出

# softmax 函数的特征
概率分析函数
1. softmax函数的输出是0.0到1.0之间的实数。
2. softmax函数的输出值的总和是1。

# 手写数字识别
见mnist.py
分为训练、测试数据，数据又分为图像、标签，2 * 2 = 4。因此load_mnist()返回4个数据。
每张图片是28 * 28 = 784个像素。因此，训练数据的形状为 (60000, 784) ，测试数据的形状为 (10000, 784) 。
意思是60000张训练图像，10000张测试图像。
---------打印mnist数据 各长度---------
x_train： (60000, 784)
y_train： (60000,)
x_test： (10000, 784)
y_test： (10000,)

进行推理的神经网络，输入是784个（784个像素），输出是10个（0-9 10个数字）。

把数据限定到某个范围内，称为正规化（normalization）。如缩放到[0, 1]，则称为归一化（Standardization）。

# 自建模型 训练 评估
见mnist.py
keras.Sequential() 是一个用于构建神经网络模型的类。它是 Keras 库中的一个核心组件，用于定义和训练神经网络。
Sequential 模型是一种简单的线性堆叠模型，非常适合构建简单的前馈神经网络,其中每个层都只有一个输入张量和一个输出张量。
可以使用各种层，如 Dense、Conv2D、LSTM 等，来构建神经网络的结构。
每个层都有自己的参数和激活函数，用于对输入数据进行转换和处理。
以下是运行过程，cmd回显：

```python
✗ py3 mnist.py
---------打印数据集形状---------
训练集形状： (60000, 28, 28)
训练集标签形状： (60000,)
测试集形状： (10000, 28, 28)
测试集标签形状： (10000,)

/Users/sevan/www/deep-learning-from-rookie-to-abandon/venv/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)

---------开始训练模型---------
Epoch 1/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 3s 1ms/step - accuracy: 0.8744 - loss: 0.4392 - val_accuracy: 0.9602 - val_loss: 0.1370
Epoch 2/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9666 - loss: 0.1164 - val_accuracy: 0.9714 - val_loss: 0.0971
Epoch 3/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9755 - loss: 0.0788 - val_accuracy: 0.9724 - val_loss: 0.0819
Epoch 4/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9834 - loss: 0.0541 - val_accuracy: 0.9771 - val_loss: 0.0715
Epoch 5/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9875 - loss: 0.0414 - val_accuracy: 0.9760 - val_loss: 0.0778
Epoch 6/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9906 - loss: 0.0319 - val_accuracy: 0.9785 - val_loss: 0.0699
Epoch 7/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9922 - loss: 0.0254 - val_accuracy: 0.9777 - val_loss: 0.0788
Epoch 8/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9945 - loss: 0.0197 - val_accuracy: 0.9778 - val_loss: 0.0801
Epoch 9/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9953 - loss: 0.0162 - val_accuracy: 0.9776 - val_loss: 0.0794
Epoch 10/10
1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 1ms/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 0.9784 - val_loss: 0.0782

---------开始评估模型---------
313/313 ━━━━━━━━━━━━━━━━━━━━ 0s 466us/step - accuracy: 0.9749 - loss: 0.0953
测试集准确率: 0.9784
2025-05-16 16:43:06.032 Python[33751:3479379] +[IMKClient subclass]: chose IMKClient_Legacy
2025-05-16 16:43:06.032 Python[33751:3479379] +[IMKInputSession subclass]: chose IMKInputSession_Legacy
---------打印数据集形状---------
训练集形状： (60000, 28, 28)
训练集标签形状： (60000,)
测试集形状： (10000, 28, 28)
测试集标签形状： (10000,)

1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step
1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step
```

这只是基本的训练与评估，后续会详细学习。
后续还能做：
- 模型优化：

- 增加网络层数和神经元数量
- 添加卷积层（Conv2D）来提高识别准确率
- 添加 Dropout 层防止过拟合
- 尝试不同的优化器和学习率
- 数据处理优化：

- 增加数据增强（Data Augmentation）
- 尝试不同的数据预处理方法
- 实现交叉验证
- 可视化和分析：

- 绘制混淆矩阵
- 分析错误预测的案例
- 可视化网络的中间层输出
- 实用功能：

- 保存训练好的模型
- 加载已保存的模型进行预测
- 制作简单的 GUI 界面
- 尝试其他数据集：

- Fashion-MNIST（服装识别）
- CIFAR-10（彩色图像分类）
- 自定义数据集

# 保存模型
模型训练完成之后，以“mnist_model.h5”保存在当前目录下。见mnist.py save_model()。